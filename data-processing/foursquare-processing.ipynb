{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOURSQUARE PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Dataset Files\n",
    "\n",
    "This project relies on three main datasets, all of which are described below. These datasets are essential for processing and building a framework for analyzing user interactions with Points of Interest (POIs). Details about the files and their structure can also be found in the accompanying README.\n",
    "\n",
    "## 1. **dataset_TIST2015_Checkins.txt**\n",
    "This file contains all user check-ins and provides information about interactions with various venues (POIs). The data is structured into 4 columns:\n",
    "\n",
    "1. **User ID**: An anonymized identifier for the user.  \n",
    "2. **Venue ID**: The unique identifier for a venue (Foursquare).  \n",
    "3. **UTC Time**: The timestamp of the check-in in Coordinated Universal Time (UTC).  \n",
    "4. **Timezone Offset**: The offset in minutes between the check-in's local time and UTC. This can be used to calculate the local time of the check-in using:  \n",
    "   \\[\n",
    "   \\text{Local Time} = \\text{UTC Time} + \\text{Timezone Offset}\n",
    "   \\]\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **dataset_TIST2015_POIs.txt**\n",
    "This file contains metadata about the Points of Interest (POIs) and is structured into 5 columns:\n",
    "\n",
    "1. **Venue ID**: The unique identifier for the venue (Foursquare).  \n",
    "2. **Latitude**: The latitude coordinate of the venue.  \n",
    "3. **Longitude**: The longitude coordinate of the venue.  \n",
    "4. **Venue Category Name**: The name of the category associated with the venue (e.g., \"Restaurant\", \"Museum\").  \n",
    "5. **Country Code**: A two-letter ISO 3166-1 alpha-2 country code indicating the country where the venue is located.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. **dataset_TIST2015_Cities.txt**\n",
    "This file provides a list of cities and their geographic details. It is structured into 6 columns:\n",
    "\n",
    "1. **City Name**: The name of the city.  \n",
    "2. **Latitude**: The latitude coordinate of the city's center.  \n",
    "3. **Longitude**: The longitude coordinate of the city's center.  \n",
    "4. **Country Code**: A two-letter ISO 3166-1 alpha-2 country code indicating the country where the city is located.  \n",
    "5. **Country Name**: The full name of the country.  \n",
    "6. **City Type**: The classification of the city, such as \"national capital\" or \"provincial capital\".  \n",
    "\n",
    "---\n",
    "\n",
    "### Key Notes:\n",
    "- The **Check-ins** file provides interaction data, which will be mapped to specific cities and POIs using the information from the **POIs** and **Cities** files.\n",
    "- The **POIs** file links venue details (e.g., location and category) with their respective country codes.\n",
    "- The **Cities** file is used to assign POIs to cities based on geographic proximity, given the latitude and longitude of both the venue and the city center.\n",
    "\n",
    "These datasets form the foundation for processing and analysis in this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "     \n",
    "    # distance between latitudes\n",
    "    # and longitudes\n",
    "    dLat = (lat2 - lat1) * math.pi / 180.0\n",
    "    dLon = (lon2 - lon1) * math.pi / 180.0\n",
    " \n",
    "    # convert to radians\n",
    "    lat1 = (lat1) * math.pi / 180.0\n",
    "    lat2 = (lat2) * math.pi / 180.0\n",
    " \n",
    "    # apply formulae\n",
    "    a = (pow(math.sin(dLat / 2), 2) +\n",
    "         pow(math.sin(dLon / 2), 2) *\n",
    "             math.cos(lat1) * math.cos(lat2));\n",
    "    rad = 6371\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    return rad * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_file = 'data/FoursquareGlobalCheckinDataset/dataset_TIST2015_Cities.txt'\n",
    "pois_file = 'data/FoursquareGlobalCheckinDataset/dataset_TIST2015_POIs.txt'\n",
    "checkins_file = 'data/FoursquareGlobalCheckinDataset/dataset_TIST2015_Checkins.txt'\n",
    "target_countries = ['US', 'GB', 'JP']\n",
    "target_cities = ['New York', 'London', 'Tokyo']\n",
    "non_target_categories = ['Residential Building (Apartment / Condo)', 'College Residence Hall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Process `dataset_TIST2015_Cities.txt`\n",
    "- **Read the `dataset_TIST2015_Cities.txt` file** containing city information.\n",
    "- **Create a dictionary** with the city name as the key and the coordinates (latitude and longitude) as the value.\n",
    "- **Create a second dictionary** for countries, where the key is the country code (ISO 3166-1 alpha-2) and the value is a list of cities that belong to that country. Each city is added to the countryâ€™s list as it is read from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cities(file_path):\n",
    "    city_dict = {}\n",
    "    country_dict = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            city_name, lat, lon, country_code, *_ = row\n",
    "            lat, lon = float(lat), float(lon)\n",
    "            city_dict[city_name] = (lat, lon) # city dictionary: {city name: (latitude, longitude)}\n",
    "            if country_code not in country_dict:\n",
    "                country_dict[country_code] = []\n",
    "            country_dict[country_code].append(city_name) # country dictionary: {country code: list of cities in that country}\n",
    "    return city_dict, country_dict\n",
    "\n",
    "city_dict, country_dict = process_cities(cities_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Process `dataset_TIST2015_POIs.txt`\n",
    "- **Read the `dataset_TIST2015_POIs.txt` file** containing the information about the POIs.\n",
    "- For each **Point of Interest**, use the country code to find the cities belonging to that country using the dictionary created in Step 1.\n",
    "- **Calculate the distance** between the POI and all cities in the country and select the city with the shortest distance. This allows us to determine which city the POI belongs to.\n",
    "- Assign a **new ID** to each POI (as an integer) and create a new file containing the following data:\n",
    "<Old_Foursquare_ID> <New_ID> <Latitude> <Longitude> <CountryCode_City>\n",
    "- **Filter out POIs** applying the following filters:\n",
    "    1. **Country Filter**: Only POIs located in the target countries (US, GB, JP) are included.\n",
    "    2. **City Filter**: Only POIs located in the target cities (New York, London, Tokyo) are included.\n",
    "    3. **Category Filter**: POIs belonging to the categories \"Residential Building (Apartment / Condo)\" and \"College Residence Hall\" are excluded.\n",
    "\n",
    "The new ID is an integer rather than the original Foursquare ID (which is a string) because working with integers is generally easier for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pois(file_path, city_dict, country_dict, target_countries, target_cities, non_target_categories):\n",
    "    pois = []\n",
    "    map_id = {}\n",
    "    new_id = 1\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            venue_id, lat, lon, category, country_code = row\n",
    "            lat, lon = float(lat), float(lon)\n",
    "            if country_code in target_countries:\n",
    "                cities = country_dict[country_code]\n",
    "                min_distance = float('inf')\n",
    "                closest_city = None\n",
    "                for city in cities:\n",
    "                    city_lat, city_lon = city_dict[city]\n",
    "                    distance = haversine(lat, lon, city_lat, city_lon)\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        closest_city = city\n",
    "                if closest_city:\n",
    "                    if closest_city in target_cities and category not in non_target_categories:\n",
    "                        pois.append((venue_id, new_id, lat, lon, country_code, closest_city))\n",
    "                        map_id[venue_id] = new_id\n",
    "                        new_id += 1\n",
    "                        \n",
    "    return pois, map_id\n",
    "\n",
    "pois, map_id = process_pois(pois_file, city_dict, country_dict, target_countries, target_cities, non_target_categories)\n",
    "poi_dict = {poi[0]: poi for poi in pois}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file is saved at `data/FoursquareProcessed/filtered_pois.txt` and contains the following columns:\n",
    "\n",
    "1. **Old Foursquare ID**: The original identifier for the POI from Foursquare.\n",
    "2. **New ID**: A new integer identifier assigned to the POI for easier processing.\n",
    "3. **Latitude**: The latitude coordinate of the POI.\n",
    "4. **Longitude**: The longitude coordinate of the POI.\n",
    "5. **Country Code**: The two-letter ISO 3166-1 alpha-2 country code indicating the country where the POI is located.\n",
    "6. **City**: The name of the city to which the POI belongs.\n",
    "\n",
    "This file is essential for mapping user check-ins to specific POIs and their corresponding cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pois(pois, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        for poi in pois:\n",
    "            file.write(\"\\t\".join(map(str, poi)) + \"\\n\")\n",
    "\n",
    "save_pois(pois, 'data/FoursquareProcessed/filtered_pois.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_venue_id_mappings(map_id, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        for old, new in map_id.items():\n",
    "            file.write(f\"{old}\\t{new}\\n\")\n",
    "\n",
    "save_venue_id_mappings(map_id, 'data/FoursquareProcessed/venue_id_mappings.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Process `dataset_TIST2015_Checkins.txt`\n",
    "- **Read the `dataset_TIST2015_Checkins.txt` file** containing user check-in data.\n",
    "- For each check-in, determine the corresponding **city** by mapping the POI to a city.\n",
    "- Use the **new IDs** (assigned in Step 2) rather than Foursquare's IDs.\n",
    "- **Convert the check-in timestamps** to a consistent timestamp format for easier processing.\n",
    "- **Filter out POIs** that do not belong to New York, Tokyo or London, ignoring those check-ins for now.\n",
    "- **Output** a file for each city (New York, Tokyo or London)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_checkins(file_path, target_cities, output_files, output_files_agg):\n",
    "    \n",
    "    city_files = {city: open(output_files[city], 'w') for city in target_cities}\n",
    "    city_agg_files = {city: open(output_files_agg[city], 'w') for city in target_cities}\n",
    "    user_scores = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))  # {user_id: {city: {poi_id: score}}}\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            user_id, venue_id, utc_time, offset = row\n",
    "            if venue_id in poi_dict:\n",
    "                poi = poi_dict[venue_id]\n",
    "                city = poi[5]\n",
    "                if city in target_cities:\n",
    "\n",
    "                    utc_dt = datetime.strptime(utc_time, '%a %b %d %H:%M:%S +0000 %Y')\n",
    "                    local_dt = utc_dt + timedelta(minutes=int(offset))\n",
    "                    timestamp = int(local_dt.timestamp())\n",
    "\n",
    "                    city_files[city].write(f\"{user_id}\\t{poi[1]}\\t{timestamp}\\n\")\n",
    "\n",
    "                    user_scores[user_id][city][poi[1]] += 1\n",
    "\n",
    "    for file in city_files.values():\n",
    "        file.close()\n",
    "\n",
    "    for user_id, city_visits in user_scores.items():\n",
    "        for city, poi_visits in city_visits.items():\n",
    "            for poi_id, score in poi_visits.items():\n",
    "                city_agg_files[city].write(f\"{user_id}\\t{poi_id}\\t{score}\\n\")\n",
    "\n",
    "    for file in city_agg_files.values():\n",
    "        file.close()\n",
    "\n",
    "output_files = {city: f\"data/FoursquareProcessed/{city}_checkins.txt\" for city in target_cities}\n",
    "output_files_agg = {city: f\"data/FoursquareProcessed/{city}_checkins_agg.txt\" for city in target_cities}\n",
    "process_checkins(checkins_file, target_cities, output_files, output_files_agg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script processes check-in data and generates two types of files for each target city:\n",
    "\n",
    "1. **Raw Check-ins Files**:\n",
    "   - Location: `data/FoursquareProcessed/<city>_checkins.txt`\n",
    "   - Content:\n",
    "     - **User ID**: Anonymized identifier for the user.\n",
    "     - **POI ID**: Numeric identifier for the Point of Interest (POI) visited by the user.\n",
    "     - **Timestamp**: UNIX timestamp of the check-in.\n",
    "\n",
    "2. **Aggregated Check-ins Files**:\n",
    "   - Location: `data/FoursquareProcessed/<city>_checkins_agg.txt`\n",
    "   - Content:\n",
    "     - **User ID**: Anonymized identifier for the user.\n",
    "     - **POI ID**: Numeric identifier for the POI.\n",
    "     - **Score**: Frequency of visits by the user to the POI, representing their interaction level.\n",
    "\n",
    "These files are useful for analyzing individual check-ins as well as aggregated user preferences for specific POIs within each city.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
